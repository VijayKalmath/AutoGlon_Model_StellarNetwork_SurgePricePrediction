{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f558a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14743bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/climate_change/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42d763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple preprocessing\n",
    "\n",
    "df[\"sponsor\"] = df[\"fee_account\"].notna().astype(int)\n",
    "df[\"final_fee_bid\"] = df[[\"max_fee_bid\", \"new_max_fee_bid\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1685f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3adc3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test preprocessing\n",
    "\n",
    "test_df[\"sponsor\"] = test_df[\"fee_account\"].notna().astype(int)\n",
    "test_df[\"final_fee_bid\"] = test_df[[\"max_fee_bid\", \"new_max_fee_bid\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656931aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not included prior closed at and surge_price_ind\n",
    "\n",
    "features = [\"prior_ledger_sequence\",  \n",
    "            \"prior_operation_count\",\n",
    "            \"prior_max_fee_charged\",\n",
    "            \"prior_min_fee_charged\",\n",
    "            \"prior_avg_fee_charged\",\n",
    "            \"transaction_operation_count\",\n",
    "            \"sponsor\",\n",
    "            \"final_fee_bid\",\n",
    "            \"fee_charged\"\n",
    "           ]\n",
    "target = \"fee_charged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7445bf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior_ledger_sequence</th>\n",
       "      <th>prior_operation_count</th>\n",
       "      <th>prior_max_fee_charged</th>\n",
       "      <th>prior_min_fee_charged</th>\n",
       "      <th>prior_avg_fee_charged</th>\n",
       "      <th>transaction_operation_count</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>final_fee_bid</th>\n",
       "      <th>fee_charged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40361493</td>\n",
       "      <td>960</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>173.285199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40365822</td>\n",
       "      <td>950</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>185.546875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40355709</td>\n",
       "      <td>988</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>188.549618</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40349273</td>\n",
       "      <td>921</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>204.212860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40347822</td>\n",
       "      <td>914</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>232.569975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091399</th>\n",
       "      <td>40355385</td>\n",
       "      <td>929</td>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "      <td>158.262351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10003.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091400</th>\n",
       "      <td>40355224</td>\n",
       "      <td>859</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>164.435946</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091401</th>\n",
       "      <td>40362999</td>\n",
       "      <td>946</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>207.456140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091402</th>\n",
       "      <td>40349121</td>\n",
       "      <td>981</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>194.642857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091403</th>\n",
       "      <td>40356022</td>\n",
       "      <td>950</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>174.311927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10091404 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          prior_ledger_sequence  prior_operation_count  prior_max_fee_charged  \\\n",
       "0                      40361493                    960                  10000   \n",
       "1                      40365822                    950                  10000   \n",
       "2                      40355709                    988                  10000   \n",
       "3                      40349273                    921                  10000   \n",
       "4                      40347822                    914                  10000   \n",
       "...                         ...                    ...                    ...   \n",
       "10091399               40355385                    929                   8000   \n",
       "10091400               40355224                    859                  10000   \n",
       "10091401               40362999                    946                  10000   \n",
       "10091402               40349121                    981                  10000   \n",
       "10091403               40356022                    950                  10000   \n",
       "\n",
       "          prior_min_fee_charged  prior_avg_fee_charged  \\\n",
       "0                           100             173.285199   \n",
       "1                           100             185.546875   \n",
       "2                           100             188.549618   \n",
       "3                           100             204.212860   \n",
       "4                           100             232.569975   \n",
       "...                         ...                    ...   \n",
       "10091399                    100             158.262351   \n",
       "10091400                    100             164.435946   \n",
       "10091401                    100             207.456140   \n",
       "10091402                    100             194.642857   \n",
       "10091403                    100             174.311927   \n",
       "\n",
       "          transaction_operation_count  sponsor  final_fee_bid  fee_charged  \n",
       "0                                   1        0          110.0          100  \n",
       "1                                   1        0          110.0          100  \n",
       "2                                   1        0          110.0          100  \n",
       "3                                   1        0          110.0          100  \n",
       "4                                   1        0          110.0          100  \n",
       "...                               ...      ...            ...          ...  \n",
       "10091399                            1        0        10003.0         1000  \n",
       "10091400                            1        0        20000.0          110  \n",
       "10091401                            1        0        20000.0          100  \n",
       "10091402                            1        0        20000.0         1000  \n",
       "10091403                            1        0        20000.0         5000  \n",
       "\n",
       "[10091404 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7aac4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure that the model only predictive values \n",
    "\n",
    "df[\"fee_charged\"] = df[\"fee_charged\"] / 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4fb22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fee_charged\"]  = np.log(df[\"fee_charged\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fab9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = TabularDataset(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4bd9dd8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'ag_args_fit': {'num_gpus': 1}, 'auto_stack': True}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'quantile_levels': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving agModels-regression_Best_Quality/learner.pkl\n",
      "Saving agModels-regression_Best_Quality/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 10800s\n",
      "AutoGluon will save models to \"agModels-regression_Best_Quality/\"\n",
      "AutoGluon Version:  0.4.1b20220417\n",
      "Python Version:     3.8.0\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    10091404\n",
      "Train Data Columns: 8\n",
      "Label Column: fee_charged\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (9.903487552536127, 0.0, 0.68942, 1.10414)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18543.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 645.85 MB (3.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int64', 'int')     : 6 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])   : 6 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\t3.0s = Fit runtime\n",
      "\t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\t1.6s = Fit runtime\n",
      "\t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\t1.6s = Fit runtime\n",
      "\t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t\t\t2.5s = Fit runtime\n",
      "\t\t\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t('int64', 'int')     : 6 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t('int', [])   : 6 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t('int64', 'int')     : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t('int8', 'int')      : 1 | ['sponsor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "\t\t('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "\t\t('int', ['bool']) : 1 | ['sponsor']\n",
      "\t12.0s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 575.21 MB (3.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 14.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving agModels-regression_Best_Quality/learner.pkl\n",
      "Saving agModels-regression_Best_Quality/utils/data/X.pkl\n",
      "Saving agModels-regression_Best_Quality/utils/data/y.pkl\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 7188.44s of the 10785.34s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 8\n",
      "\t0.37s \t= Train Time (Using 10000/10091404 rows) (7187.47s remaining time)\n",
      "\t0.35s \t= Train Time (Using 20000/10091404 rows) (7187.12s remaining time)\n",
      "\t0.4s \t= Train Time (Using 40000/10091404 rows) (7186.72s remaining time)\n",
      "\t0.45s \t= Train Time (Using 80000/10091404 rows) (7186.27s remaining time)\n",
      "\t0.56s \t= Train Time (Using 160000/10091404 rows) (7185.71s remaining time)\n",
      "\t0.83s \t= Train Time (Using 320000/10091404 rows) (7184.88s remaining time)\n",
      "\t1.56s \t= Train Time (Using 640000/10091404 rows) (7183.32s remaining time)\n",
      "\t2.97s \t= Train Time (Using 1280000/10091404 rows) (7180.35s remaining time)\n",
      "\t6.58s \t= Train Time (Using 2560000/10091404 rows) (7173.78s remaining time)\n",
      "\t14.36s \t= Train Time (Using 5120000/10091404 rows) (7159.41s remaining time)\n",
      "\t27.42s \t= Train Time (Using 10091404/10091404 rows) (7131.99s remaining time)\n",
      "\t665.55s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t-0.3052\t = Validation score   (root_mean_squared_error)\n",
      "\t57.25s\t = Training   runtime\n",
      "\t423.26s\t = Validation runtime\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 6704.92s of the 10301.83s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 8\n",
      "\t0.36s \t= Train Time (Using 10000/10091404 rows) (6703.98s remaining time)\n",
      "\t0.39s \t= Train Time (Using 20000/10091404 rows) (6703.59s remaining time)\n",
      "\t0.4s \t= Train Time (Using 40000/10091404 rows) (6703.19s remaining time)\n",
      "\t0.49s \t= Train Time (Using 80000/10091404 rows) (6702.7s remaining time)\n",
      "\t0.58s \t= Train Time (Using 160000/10091404 rows) (6702.12s remaining time)\n",
      "\t0.87s \t= Train Time (Using 320000/10091404 rows) (6701.26s remaining time)\n",
      "\t1.53s \t= Train Time (Using 640000/10091404 rows) (6699.72s remaining time)\n",
      "\t3.1s \t= Train Time (Using 1280000/10091404 rows) (6696.62s remaining time)\n",
      "\t6.55s \t= Train Time (Using 2560000/10091404 rows) (6690.07s remaining time)\n",
      "\t14.67s \t= Train Time (Using 5120000/10091404 rows) (6675.4s remaining time)\n",
      "\t28.1s \t= Train Time (Using 10091404/10091404 rows) (6647.31s remaining time)\n",
      "\t589.78s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t-0.2563\t = Validation score   (root_mean_squared_error)\n",
      "\t58.41s\t = Training   runtime\n",
      "\t460.7s\t = Validation runtime\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6182.76s of the 9779.67s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.860789\n",
      "[100]\tvalid_set's rmse: 0.830374\n",
      "[150]\tvalid_set's rmse: 0.807223\n",
      "[200]\tvalid_set's rmse: 0.79642\n",
      "[250]\tvalid_set's rmse: 0.787243\n",
      "[300]\tvalid_set's rmse: 0.780949\n",
      "[350]\tvalid_set's rmse: 0.776238\n",
      "[400]\tvalid_set's rmse: 0.771205\n",
      "[450]\tvalid_set's rmse: 0.767624\n",
      "[500]\tvalid_set's rmse: 0.764561\n",
      "[550]\tvalid_set's rmse: 0.761155\n",
      "[600]\tvalid_set's rmse: 0.758144\n",
      "[650]\tvalid_set's rmse: 0.755415\n",
      "[700]\tvalid_set's rmse: 0.753032\n",
      "[750]\tvalid_set's rmse: 0.750945\n",
      "[800]\tvalid_set's rmse: 0.748831\n",
      "[850]\tvalid_set's rmse: 0.746627\n",
      "[900]\tvalid_set's rmse: 0.744871\n",
      "[950]\tvalid_set's rmse: 0.74294\n",
      "[1000]\tvalid_set's rmse: 0.741313\n",
      "[1050]\tvalid_set's rmse: 0.739745\n",
      "[1100]\tvalid_set's rmse: 0.73808\n",
      "[1150]\tvalid_set's rmse: 0.736757\n",
      "[1200]\tvalid_set's rmse: 0.735559\n",
      "[1250]\tvalid_set's rmse: 0.733825\n",
      "[1300]\tvalid_set's rmse: 0.732389\n",
      "[1350]\tvalid_set's rmse: 0.73099\n",
      "[1400]\tvalid_set's rmse: 0.729544\n",
      "[1450]\tvalid_set's rmse: 0.728427\n",
      "[1500]\tvalid_set's rmse: 0.72722\n",
      "[1550]\tvalid_set's rmse: 0.72605\n",
      "[1600]\tvalid_set's rmse: 0.724881\n",
      "[1650]\tvalid_set's rmse: 0.723734\n",
      "[1700]\tvalid_set's rmse: 0.722498\n",
      "[1750]\tvalid_set's rmse: 0.721443\n",
      "[1800]\tvalid_set's rmse: 0.720402\n",
      "[1850]\tvalid_set's rmse: 0.719273\n",
      "[1900]\tvalid_set's rmse: 0.718229\n",
      "[1950]\tvalid_set's rmse: 0.717243\n",
      "[2000]\tvalid_set's rmse: 0.716394\n",
      "[2050]\tvalid_set's rmse: 0.715414\n",
      "[2100]\tvalid_set's rmse: 0.714442\n",
      "[2150]\tvalid_set's rmse: 0.713307\n",
      "[2200]\tvalid_set's rmse: 0.712253\n",
      "[2250]\tvalid_set's rmse: 0.711516\n",
      "[2300]\tvalid_set's rmse: 0.710583\n",
      "[2350]\tvalid_set's rmse: 0.709772\n",
      "[2400]\tvalid_set's rmse: 0.708825\n",
      "[2450]\tvalid_set's rmse: 0.707917\n",
      "[2500]\tvalid_set's rmse: 0.706971\n",
      "[2550]\tvalid_set's rmse: 0.706169\n",
      "[2600]\tvalid_set's rmse: 0.705336\n",
      "[2650]\tvalid_set's rmse: 0.70454\n",
      "[2700]\tvalid_set's rmse: 0.703775\n",
      "[2750]\tvalid_set's rmse: 0.702926\n",
      "[2800]\tvalid_set's rmse: 0.702066\n",
      "[2850]\tvalid_set's rmse: 0.701263\n",
      "[2900]\tvalid_set's rmse: 0.70047\n",
      "[2950]\tvalid_set's rmse: 0.69973\n",
      "[3000]\tvalid_set's rmse: 0.698964\n",
      "[3050]\tvalid_set's rmse: 0.698021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3081. Best iteration is:\n",
      "\t[3081]\tvalid_set's rmse: 0.6977\n",
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.85175\n",
      "[100]\tvalid_set's rmse: 0.815366\n",
      "[150]\tvalid_set's rmse: 0.799752\n",
      "[200]\tvalid_set's rmse: 0.78978\n",
      "[250]\tvalid_set's rmse: 0.782482\n",
      "[300]\tvalid_set's rmse: 0.77733\n",
      "[350]\tvalid_set's rmse: 0.77229\n",
      "[400]\tvalid_set's rmse: 0.768164\n",
      "[450]\tvalid_set's rmse: 0.764239\n",
      "[500]\tvalid_set's rmse: 0.761446\n",
      "[550]\tvalid_set's rmse: 0.758839\n",
      "[600]\tvalid_set's rmse: 0.7565\n",
      "[650]\tvalid_set's rmse: 0.753915\n",
      "[700]\tvalid_set's rmse: 0.751511\n",
      "[750]\tvalid_set's rmse: 0.749422\n",
      "[800]\tvalid_set's rmse: 0.747262\n",
      "[850]\tvalid_set's rmse: 0.745525\n",
      "[900]\tvalid_set's rmse: 0.743807\n",
      "[950]\tvalid_set's rmse: 0.74227\n",
      "[1000]\tvalid_set's rmse: 0.740772\n",
      "[1050]\tvalid_set's rmse: 0.738954\n",
      "[1100]\tvalid_set's rmse: 0.73718\n",
      "[1150]\tvalid_set's rmse: 0.735759\n",
      "[1200]\tvalid_set's rmse: 0.734481\n",
      "[1250]\tvalid_set's rmse: 0.733011\n",
      "[1300]\tvalid_set's rmse: 0.731659\n",
      "[1350]\tvalid_set's rmse: 0.730072\n",
      "[1400]\tvalid_set's rmse: 0.728674\n",
      "[1450]\tvalid_set's rmse: 0.727398\n",
      "[1500]\tvalid_set's rmse: 0.726281\n",
      "[1550]\tvalid_set's rmse: 0.725048\n",
      "[1600]\tvalid_set's rmse: 0.723977\n",
      "[1650]\tvalid_set's rmse: 0.722648\n",
      "[1700]\tvalid_set's rmse: 0.721413\n",
      "[1750]\tvalid_set's rmse: 0.720162\n",
      "[1800]\tvalid_set's rmse: 0.719068\n",
      "[1850]\tvalid_set's rmse: 0.717867\n",
      "[1900]\tvalid_set's rmse: 0.716623\n",
      "[1950]\tvalid_set's rmse: 0.71572\n",
      "[2000]\tvalid_set's rmse: 0.714622\n",
      "[2050]\tvalid_set's rmse: 0.713632\n",
      "[2100]\tvalid_set's rmse: 0.712741\n",
      "[2150]\tvalid_set's rmse: 0.711567\n",
      "[2200]\tvalid_set's rmse: 0.710687\n",
      "[2250]\tvalid_set's rmse: 0.709521\n",
      "[2300]\tvalid_set's rmse: 0.708431\n",
      "[2350]\tvalid_set's rmse: 0.707499\n",
      "[2400]\tvalid_set's rmse: 0.706669\n",
      "[2450]\tvalid_set's rmse: 0.705751\n",
      "[2500]\tvalid_set's rmse: 0.704935\n",
      "[2550]\tvalid_set's rmse: 0.704151\n",
      "[2600]\tvalid_set's rmse: 0.70325\n",
      "[2650]\tvalid_set's rmse: 0.70249\n",
      "[2700]\tvalid_set's rmse: 0.701664\n",
      "[2750]\tvalid_set's rmse: 0.700837\n",
      "[2800]\tvalid_set's rmse: 0.700031\n",
      "[2850]\tvalid_set's rmse: 0.699411\n",
      "[2900]\tvalid_set's rmse: 0.698587\n",
      "[2950]\tvalid_set's rmse: 0.697888\n",
      "[3000]\tvalid_set's rmse: 0.696949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3017. Best iteration is:\n",
      "\t[3017]\tvalid_set's rmse: 0.696703\n",
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.86863\n",
      "[100]\tvalid_set's rmse: 0.833041\n",
      "[150]\tvalid_set's rmse: 0.810132\n",
      "[200]\tvalid_set's rmse: 0.796442\n",
      "[250]\tvalid_set's rmse: 0.78725\n",
      "[300]\tvalid_set's rmse: 0.780819\n",
      "[350]\tvalid_set's rmse: 0.774717\n",
      "[400]\tvalid_set's rmse: 0.770208\n",
      "[450]\tvalid_set's rmse: 0.765709\n",
      "[500]\tvalid_set's rmse: 0.762207\n",
      "[550]\tvalid_set's rmse: 0.759491\n",
      "[600]\tvalid_set's rmse: 0.756796\n",
      "[650]\tvalid_set's rmse: 0.754435\n",
      "[700]\tvalid_set's rmse: 0.752129\n",
      "[750]\tvalid_set's rmse: 0.749804\n",
      "[800]\tvalid_set's rmse: 0.747512\n",
      "[850]\tvalid_set's rmse: 0.745995\n",
      "[900]\tvalid_set's rmse: 0.744497\n",
      "[950]\tvalid_set's rmse: 0.742702\n",
      "[1000]\tvalid_set's rmse: 0.740959\n",
      "[1050]\tvalid_set's rmse: 0.739324\n",
      "[1100]\tvalid_set's rmse: 0.737884\n",
      "[1150]\tvalid_set's rmse: 0.736442\n",
      "[1200]\tvalid_set's rmse: 0.734951\n",
      "[1250]\tvalid_set's rmse: 0.733403\n",
      "[1300]\tvalid_set's rmse: 0.732049\n",
      "[1350]\tvalid_set's rmse: 0.730318\n",
      "[1400]\tvalid_set's rmse: 0.728987\n",
      "[1450]\tvalid_set's rmse: 0.727725\n",
      "[1500]\tvalid_set's rmse: 0.726474\n",
      "[1550]\tvalid_set's rmse: 0.725218\n",
      "[1600]\tvalid_set's rmse: 0.724032\n",
      "[1650]\tvalid_set's rmse: 0.72298\n",
      "[1700]\tvalid_set's rmse: 0.721687\n",
      "[1750]\tvalid_set's rmse: 0.720584\n",
      "[1800]\tvalid_set's rmse: 0.719672\n",
      "[1850]\tvalid_set's rmse: 0.718489\n",
      "[1900]\tvalid_set's rmse: 0.717397\n",
      "[1950]\tvalid_set's rmse: 0.7164\n",
      "[2000]\tvalid_set's rmse: 0.715328\n",
      "[2050]\tvalid_set's rmse: 0.714281\n",
      "[2100]\tvalid_set's rmse: 0.713348\n",
      "[2150]\tvalid_set's rmse: 0.712443\n",
      "[2200]\tvalid_set's rmse: 0.711614\n",
      "[2250]\tvalid_set's rmse: 0.710479\n",
      "[2300]\tvalid_set's rmse: 0.709516\n",
      "[2350]\tvalid_set's rmse: 0.708644\n",
      "[2400]\tvalid_set's rmse: 0.707696\n",
      "[2450]\tvalid_set's rmse: 0.706685\n",
      "[2500]\tvalid_set's rmse: 0.705629\n",
      "[2550]\tvalid_set's rmse: 0.704791\n",
      "[2600]\tvalid_set's rmse: 0.703789\n",
      "[2650]\tvalid_set's rmse: 0.703008\n",
      "[2700]\tvalid_set's rmse: 0.702304\n",
      "[2750]\tvalid_set's rmse: 0.701536\n",
      "[2800]\tvalid_set's rmse: 0.700656\n",
      "[2850]\tvalid_set's rmse: 0.699888\n",
      "[2900]\tvalid_set's rmse: 0.699129\n",
      "[2950]\tvalid_set's rmse: 0.698342\n",
      "[3000]\tvalid_set's rmse: 0.697511\n",
      "[3050]\tvalid_set's rmse: 0.696816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3093. Best iteration is:\n",
      "\t[3093]\tvalid_set's rmse: 0.696115\n",
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.860386\n",
      "[100]\tvalid_set's rmse: 0.82255\n",
      "[150]\tvalid_set's rmse: 0.803013\n",
      "[200]\tvalid_set's rmse: 0.792812\n",
      "[250]\tvalid_set's rmse: 0.785175\n",
      "[300]\tvalid_set's rmse: 0.778013\n",
      "[350]\tvalid_set's rmse: 0.773048\n",
      "[400]\tvalid_set's rmse: 0.769092\n",
      "[450]\tvalid_set's rmse: 0.765356\n",
      "[500]\tvalid_set's rmse: 0.76207\n",
      "[550]\tvalid_set's rmse: 0.759369\n",
      "[600]\tvalid_set's rmse: 0.756674\n",
      "[650]\tvalid_set's rmse: 0.754159\n",
      "[700]\tvalid_set's rmse: 0.752052\n",
      "[750]\tvalid_set's rmse: 0.749647\n",
      "[800]\tvalid_set's rmse: 0.747418\n",
      "[850]\tvalid_set's rmse: 0.74568\n",
      "[900]\tvalid_set's rmse: 0.743924\n",
      "[950]\tvalid_set's rmse: 0.742446\n",
      "[1000]\tvalid_set's rmse: 0.740879\n",
      "[1050]\tvalid_set's rmse: 0.739386\n",
      "[1100]\tvalid_set's rmse: 0.737835\n",
      "[1150]\tvalid_set's rmse: 0.736369\n",
      "[1200]\tvalid_set's rmse: 0.735053\n",
      "[1250]\tvalid_set's rmse: 0.733815\n",
      "[1300]\tvalid_set's rmse: 0.732479\n",
      "[1350]\tvalid_set's rmse: 0.73115\n",
      "[1400]\tvalid_set's rmse: 0.729703\n",
      "[1450]\tvalid_set's rmse: 0.728563\n",
      "[1500]\tvalid_set's rmse: 0.727396\n",
      "[1550]\tvalid_set's rmse: 0.726232\n",
      "[1600]\tvalid_set's rmse: 0.725037\n",
      "[1650]\tvalid_set's rmse: 0.723829\n",
      "[1700]\tvalid_set's rmse: 0.722801\n",
      "[1750]\tvalid_set's rmse: 0.721678\n",
      "[1800]\tvalid_set's rmse: 0.7206\n",
      "[1850]\tvalid_set's rmse: 0.719655\n",
      "[1900]\tvalid_set's rmse: 0.718517\n",
      "[1950]\tvalid_set's rmse: 0.717413\n",
      "[2000]\tvalid_set's rmse: 0.716451\n",
      "[2050]\tvalid_set's rmse: 0.715414\n",
      "[2100]\tvalid_set's rmse: 0.714451\n",
      "[2150]\tvalid_set's rmse: 0.713322\n",
      "[2200]\tvalid_set's rmse: 0.712318\n",
      "[2250]\tvalid_set's rmse: 0.711343\n",
      "[2300]\tvalid_set's rmse: 0.71063\n",
      "[2350]\tvalid_set's rmse: 0.70966\n",
      "[2400]\tvalid_set's rmse: 0.708682\n",
      "[2450]\tvalid_set's rmse: 0.707582\n",
      "[2500]\tvalid_set's rmse: 0.706702\n",
      "[2550]\tvalid_set's rmse: 0.705783\n",
      "[2600]\tvalid_set's rmse: 0.704677\n",
      "[2650]\tvalid_set's rmse: 0.703978\n",
      "[2700]\tvalid_set's rmse: 0.703101\n",
      "[2750]\tvalid_set's rmse: 0.702162\n",
      "[2800]\tvalid_set's rmse: 0.70146\n",
      "[2850]\tvalid_set's rmse: 0.700705\n",
      "[2900]\tvalid_set's rmse: 0.699876\n",
      "[2950]\tvalid_set's rmse: 0.698955\n",
      "[3000]\tvalid_set's rmse: 0.698068\n",
      "[3050]\tvalid_set's rmse: 0.697286\n",
      "[3100]\tvalid_set's rmse: 0.696663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3133. Best iteration is:\n",
      "\t[3133]\tvalid_set's rmse: 0.696077\n",
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.872648\n",
      "[100]\tvalid_set's rmse: 0.834008\n",
      "[150]\tvalid_set's rmse: 0.809771\n",
      "[200]\tvalid_set's rmse: 0.794993\n",
      "[250]\tvalid_set's rmse: 0.78591\n",
      "[300]\tvalid_set's rmse: 0.780343\n",
      "[350]\tvalid_set's rmse: 0.774865\n",
      "[400]\tvalid_set's rmse: 0.770274\n",
      "[450]\tvalid_set's rmse: 0.766083\n",
      "[500]\tvalid_set's rmse: 0.76243\n",
      "[550]\tvalid_set's rmse: 0.759385\n",
      "[600]\tvalid_set's rmse: 0.756315\n",
      "[650]\tvalid_set's rmse: 0.753711\n",
      "[700]\tvalid_set's rmse: 0.751492\n",
      "[750]\tvalid_set's rmse: 0.749613\n",
      "[800]\tvalid_set's rmse: 0.747485\n",
      "[850]\tvalid_set's rmse: 0.74563\n",
      "[900]\tvalid_set's rmse: 0.744042\n",
      "[950]\tvalid_set's rmse: 0.742171\n",
      "[1000]\tvalid_set's rmse: 0.740669\n",
      "[1050]\tvalid_set's rmse: 0.73916\n",
      "[1100]\tvalid_set's rmse: 0.737738\n",
      "[1150]\tvalid_set's rmse: 0.736225\n",
      "[1200]\tvalid_set's rmse: 0.734914\n",
      "[1250]\tvalid_set's rmse: 0.733417\n",
      "[1300]\tvalid_set's rmse: 0.732134\n",
      "[1350]\tvalid_set's rmse: 0.730761\n",
      "[1400]\tvalid_set's rmse: 0.729594\n",
      "[1450]\tvalid_set's rmse: 0.728368\n",
      "[1500]\tvalid_set's rmse: 0.727045\n",
      "[1550]\tvalid_set's rmse: 0.725998\n",
      "[1600]\tvalid_set's rmse: 0.72476\n",
      "[1650]\tvalid_set's rmse: 0.723611\n",
      "[1700]\tvalid_set's rmse: 0.722573\n",
      "[1750]\tvalid_set's rmse: 0.721434\n",
      "[1800]\tvalid_set's rmse: 0.720491\n",
      "[1850]\tvalid_set's rmse: 0.719428\n",
      "[1900]\tvalid_set's rmse: 0.718283\n",
      "[1950]\tvalid_set's rmse: 0.717224\n",
      "[2000]\tvalid_set's rmse: 0.716062\n",
      "[2050]\tvalid_set's rmse: 0.71513\n",
      "[2100]\tvalid_set's rmse: 0.714165\n",
      "[2150]\tvalid_set's rmse: 0.713153\n",
      "[2200]\tvalid_set's rmse: 0.711996\n",
      "[2250]\tvalid_set's rmse: 0.711023\n",
      "[2300]\tvalid_set's rmse: 0.710142\n",
      "[2350]\tvalid_set's rmse: 0.709214\n",
      "[2400]\tvalid_set's rmse: 0.708209\n",
      "[2450]\tvalid_set's rmse: 0.707351\n",
      "[2500]\tvalid_set's rmse: 0.706554\n",
      "[2550]\tvalid_set's rmse: 0.705652\n",
      "[2600]\tvalid_set's rmse: 0.70464\n",
      "[2650]\tvalid_set's rmse: 0.703738\n",
      "[2700]\tvalid_set's rmse: 0.702818\n",
      "[2750]\tvalid_set's rmse: 0.70205\n",
      "[2800]\tvalid_set's rmse: 0.701144\n",
      "[2850]\tvalid_set's rmse: 0.700321\n",
      "[2900]\tvalid_set's rmse: 0.69951\n",
      "[2950]\tvalid_set's rmse: 0.698698\n",
      "[3000]\tvalid_set's rmse: 0.697935\n",
      "[3050]\tvalid_set's rmse: 0.697233\n",
      "[3100]\tvalid_set's rmse: 0.696593\n",
      "[3150]\tvalid_set's rmse: 0.695882\n",
      "[3200]\tvalid_set's rmse: 0.69519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3205. Best iteration is:\n",
      "\t[3205]\tvalid_set's rmse: 0.695145\n",
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.868886\n",
      "[100]\tvalid_set's rmse: 0.830355\n",
      "[150]\tvalid_set's rmse: 0.807451\n",
      "[200]\tvalid_set's rmse: 0.794002\n",
      "[250]\tvalid_set's rmse: 0.785191\n",
      "[300]\tvalid_set's rmse: 0.778079\n",
      "[350]\tvalid_set's rmse: 0.772733\n",
      "[400]\tvalid_set's rmse: 0.768564\n",
      "[450]\tvalid_set's rmse: 0.765099\n",
      "[500]\tvalid_set's rmse: 0.76193\n",
      "[550]\tvalid_set's rmse: 0.759048\n",
      "[600]\tvalid_set's rmse: 0.756138\n",
      "[650]\tvalid_set's rmse: 0.753876\n",
      "[700]\tvalid_set's rmse: 0.751447\n",
      "[750]\tvalid_set's rmse: 0.749351\n",
      "[800]\tvalid_set's rmse: 0.747456\n",
      "[850]\tvalid_set's rmse: 0.745438\n",
      "[900]\tvalid_set's rmse: 0.743871\n",
      "[950]\tvalid_set's rmse: 0.74218\n",
      "[1000]\tvalid_set's rmse: 0.740272\n",
      "[1050]\tvalid_set's rmse: 0.738708\n",
      "[1100]\tvalid_set's rmse: 0.736792\n",
      "[1150]\tvalid_set's rmse: 0.735298\n",
      "[1200]\tvalid_set's rmse: 0.733543\n",
      "[1250]\tvalid_set's rmse: 0.732244\n",
      "[1300]\tvalid_set's rmse: 0.730769\n",
      "[1350]\tvalid_set's rmse: 0.72938\n",
      "[1400]\tvalid_set's rmse: 0.7282\n",
      "[1450]\tvalid_set's rmse: 0.727031\n",
      "[1500]\tvalid_set's rmse: 0.725626\n",
      "[1550]\tvalid_set's rmse: 0.724422\n",
      "[1600]\tvalid_set's rmse: 0.723273\n",
      "[1650]\tvalid_set's rmse: 0.722223\n",
      "[1700]\tvalid_set's rmse: 0.721138\n",
      "[1750]\tvalid_set's rmse: 0.719584\n",
      "[1800]\tvalid_set's rmse: 0.718446\n",
      "[1850]\tvalid_set's rmse: 0.717434\n",
      "[1900]\tvalid_set's rmse: 0.716493\n",
      "[1950]\tvalid_set's rmse: 0.715356\n",
      "[2000]\tvalid_set's rmse: 0.714483\n",
      "[2050]\tvalid_set's rmse: 0.713538\n",
      "[2100]\tvalid_set's rmse: 0.712519\n",
      "[2150]\tvalid_set's rmse: 0.711361\n",
      "[2200]\tvalid_set's rmse: 0.71043\n",
      "[2250]\tvalid_set's rmse: 0.709633\n",
      "[2300]\tvalid_set's rmse: 0.708781\n",
      "[2350]\tvalid_set's rmse: 0.707608\n",
      "[2400]\tvalid_set's rmse: 0.706619\n",
      "[2450]\tvalid_set's rmse: 0.705753\n",
      "[2500]\tvalid_set's rmse: 0.704745\n",
      "[2550]\tvalid_set's rmse: 0.703812\n",
      "[2600]\tvalid_set's rmse: 0.70288\n",
      "[2650]\tvalid_set's rmse: 0.702085\n",
      "[2700]\tvalid_set's rmse: 0.701385\n",
      "[2750]\tvalid_set's rmse: 0.700508\n",
      "[2800]\tvalid_set's rmse: 0.699599\n",
      "[2850]\tvalid_set's rmse: 0.698869\n",
      "[2900]\tvalid_set's rmse: 0.698181\n",
      "[2950]\tvalid_set's rmse: 0.697251\n",
      "[3000]\tvalid_set's rmse: 0.696446\n",
      "[3050]\tvalid_set's rmse: 0.695736\n",
      "[3100]\tvalid_set's rmse: 0.694942\n",
      "[3150]\tvalid_set's rmse: 0.694289\n",
      "[3200]\tvalid_set's rmse: 0.693465\n",
      "[3250]\tvalid_set's rmse: 0.692731\n",
      "[3300]\tvalid_set's rmse: 0.692147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3312. Best iteration is:\n",
      "\t[3312]\tvalid_set's rmse: 0.691952\n",
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.869844\n",
      "[100]\tvalid_set's rmse: 0.832152\n",
      "[150]\tvalid_set's rmse: 0.80695\n",
      "[200]\tvalid_set's rmse: 0.794618\n",
      "[250]\tvalid_set's rmse: 0.786088\n",
      "[300]\tvalid_set's rmse: 0.780253\n",
      "[350]\tvalid_set's rmse: 0.77494\n",
      "[400]\tvalid_set's rmse: 0.770662\n",
      "[450]\tvalid_set's rmse: 0.766831\n",
      "[500]\tvalid_set's rmse: 0.763452\n",
      "[550]\tvalid_set's rmse: 0.76004\n",
      "[600]\tvalid_set's rmse: 0.757397\n",
      "[650]\tvalid_set's rmse: 0.754787\n",
      "[700]\tvalid_set's rmse: 0.752304\n",
      "[750]\tvalid_set's rmse: 0.749542\n",
      "[800]\tvalid_set's rmse: 0.747337\n",
      "[850]\tvalid_set's rmse: 0.745537\n",
      "[900]\tvalid_set's rmse: 0.743568\n",
      "[950]\tvalid_set's rmse: 0.74165\n",
      "[1000]\tvalid_set's rmse: 0.740107\n",
      "[1050]\tvalid_set's rmse: 0.738437\n",
      "[1100]\tvalid_set's rmse: 0.73686\n",
      "[1150]\tvalid_set's rmse: 0.735203\n",
      "[1200]\tvalid_set's rmse: 0.733802\n",
      "[1250]\tvalid_set's rmse: 0.732103\n",
      "[1300]\tvalid_set's rmse: 0.73081\n",
      "[1350]\tvalid_set's rmse: 0.729309\n",
      "[1400]\tvalid_set's rmse: 0.727919\n",
      "[1450]\tvalid_set's rmse: 0.726733\n",
      "[1500]\tvalid_set's rmse: 0.725526\n",
      "[1550]\tvalid_set's rmse: 0.724205\n",
      "[1600]\tvalid_set's rmse: 0.723072\n",
      "[1650]\tvalid_set's rmse: 0.721975\n",
      "[1700]\tvalid_set's rmse: 0.721004\n",
      "[1750]\tvalid_set's rmse: 0.720009\n",
      "[1800]\tvalid_set's rmse: 0.718887\n",
      "[1850]\tvalid_set's rmse: 0.717717\n",
      "[1900]\tvalid_set's rmse: 0.716732\n",
      "[1950]\tvalid_set's rmse: 0.715629\n",
      "[2000]\tvalid_set's rmse: 0.714572\n",
      "[2050]\tvalid_set's rmse: 0.713725\n",
      "[2100]\tvalid_set's rmse: 0.712852\n",
      "[2150]\tvalid_set's rmse: 0.711891\n",
      "[2200]\tvalid_set's rmse: 0.710894\n",
      "[2250]\tvalid_set's rmse: 0.709966\n",
      "[2300]\tvalid_set's rmse: 0.709077\n",
      "[2350]\tvalid_set's rmse: 0.70814\n",
      "[2400]\tvalid_set's rmse: 0.707182\n",
      "[2450]\tvalid_set's rmse: 0.70633\n",
      "[2500]\tvalid_set's rmse: 0.705522\n",
      "[2550]\tvalid_set's rmse: 0.70462\n",
      "[2600]\tvalid_set's rmse: 0.7038\n",
      "[2650]\tvalid_set's rmse: 0.702936\n",
      "[2700]\tvalid_set's rmse: 0.701905\n",
      "[2750]\tvalid_set's rmse: 0.701022\n",
      "[2800]\tvalid_set's rmse: 0.700215\n",
      "[2850]\tvalid_set's rmse: 0.699358\n",
      "[2900]\tvalid_set's rmse: 0.69858\n",
      "[2950]\tvalid_set's rmse: 0.697808\n",
      "[3000]\tvalid_set's rmse: 0.697093\n",
      "[3050]\tvalid_set's rmse: 0.696353\n",
      "[3100]\tvalid_set's rmse: 0.695452\n",
      "[3150]\tvalid_set's rmse: 0.694746\n",
      "[3200]\tvalid_set's rmse: 0.694011\n",
      "[3250]\tvalid_set's rmse: 0.693313\n",
      "[3300]\tvalid_set's rmse: 0.692649\n",
      "[3350]\tvalid_set's rmse: 0.692047\n",
      "[3400]\tvalid_set's rmse: 0.691292\n",
      "[3450]\tvalid_set's rmse: 0.690503\n",
      "[3500]\tvalid_set's rmse: 0.689712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3520. Best iteration is:\n",
      "\t[3520]\tvalid_set's rmse: 0.689329\n",
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.858291\n",
      "[100]\tvalid_set's rmse: 0.817527\n",
      "[150]\tvalid_set's rmse: 0.803762\n",
      "[200]\tvalid_set's rmse: 0.793064\n",
      "[250]\tvalid_set's rmse: 0.782892\n",
      "[300]\tvalid_set's rmse: 0.776897\n",
      "[350]\tvalid_set's rmse: 0.772779\n",
      "[400]\tvalid_set's rmse: 0.768945\n",
      "[450]\tvalid_set's rmse: 0.765181\n",
      "[500]\tvalid_set's rmse: 0.762106\n",
      "[550]\tvalid_set's rmse: 0.759231\n",
      "[600]\tvalid_set's rmse: 0.75661\n",
      "[650]\tvalid_set's rmse: 0.7544\n",
      "[700]\tvalid_set's rmse: 0.752236\n",
      "[750]\tvalid_set's rmse: 0.750205\n",
      "[800]\tvalid_set's rmse: 0.747823\n",
      "[850]\tvalid_set's rmse: 0.745486\n",
      "[900]\tvalid_set's rmse: 0.743545\n",
      "[950]\tvalid_set's rmse: 0.741878\n",
      "[1000]\tvalid_set's rmse: 0.740301\n",
      "[1050]\tvalid_set's rmse: 0.738577\n",
      "[1100]\tvalid_set's rmse: 0.736617\n",
      "[1150]\tvalid_set's rmse: 0.735012\n",
      "[1200]\tvalid_set's rmse: 0.73349\n",
      "[1250]\tvalid_set's rmse: 0.732241\n",
      "[1300]\tvalid_set's rmse: 0.731018\n",
      "[1350]\tvalid_set's rmse: 0.729637\n",
      "[1400]\tvalid_set's rmse: 0.72847\n",
      "[1450]\tvalid_set's rmse: 0.727355\n",
      "[1500]\tvalid_set's rmse: 0.726163\n",
      "[1550]\tvalid_set's rmse: 0.72519\n",
      "[1600]\tvalid_set's rmse: 0.72399\n",
      "[1650]\tvalid_set's rmse: 0.72287\n",
      "[1700]\tvalid_set's rmse: 0.721804\n",
      "[1750]\tvalid_set's rmse: 0.720635\n",
      "[1800]\tvalid_set's rmse: 0.719543\n",
      "[1850]\tvalid_set's rmse: 0.718672\n",
      "[1900]\tvalid_set's rmse: 0.717708\n",
      "[1950]\tvalid_set's rmse: 0.716701\n",
      "[2000]\tvalid_set's rmse: 0.715614\n",
      "[2050]\tvalid_set's rmse: 0.714688\n",
      "[2100]\tvalid_set's rmse: 0.713702\n",
      "[2150]\tvalid_set's rmse: 0.712656\n",
      "[2200]\tvalid_set's rmse: 0.711791\n",
      "[2250]\tvalid_set's rmse: 0.710719\n",
      "[2300]\tvalid_set's rmse: 0.709538\n",
      "[2350]\tvalid_set's rmse: 0.708435\n",
      "[2400]\tvalid_set's rmse: 0.707277\n",
      "[2450]\tvalid_set's rmse: 0.706388\n",
      "[2500]\tvalid_set's rmse: 0.705529\n",
      "[2550]\tvalid_set's rmse: 0.704776\n",
      "[2600]\tvalid_set's rmse: 0.704042\n",
      "[2650]\tvalid_set's rmse: 0.70324\n",
      "[2700]\tvalid_set's rmse: 0.702388\n",
      "[2750]\tvalid_set's rmse: 0.701659\n",
      "[2800]\tvalid_set's rmse: 0.7009\n",
      "[2850]\tvalid_set's rmse: 0.700218\n",
      "[2900]\tvalid_set's rmse: 0.699438\n",
      "[2950]\tvalid_set's rmse: 0.698629\n",
      "[3000]\tvalid_set's rmse: 0.697814\n",
      "[3050]\tvalid_set's rmse: 0.697092\n",
      "[3100]\tvalid_set's rmse: 0.696345\n",
      "[3150]\tvalid_set's rmse: 0.695549\n",
      "[3200]\tvalid_set's rmse: 0.694671\n",
      "[3250]\tvalid_set's rmse: 0.693998\n",
      "[3300]\tvalid_set's rmse: 0.693275\n",
      "[3350]\tvalid_set's rmse: 0.692428\n",
      "[3400]\tvalid_set's rmse: 0.69169\n",
      "[3450]\tvalid_set's rmse: 0.691028\n",
      "[3500]\tvalid_set's rmse: 0.690296\n",
      "[3550]\tvalid_set's rmse: 0.689691\n",
      "[3600]\tvalid_set's rmse: 0.688964\n",
      "[3650]\tvalid_set's rmse: 0.688164\n",
      "[3700]\tvalid_set's rmse: 0.68744\n",
      "[3750]\tvalid_set's rmse: 0.686822\n",
      "[3800]\tvalid_set's rmse: 0.68619\n",
      "[3850]\tvalid_set's rmse: 0.685509\n",
      "[3900]\tvalid_set's rmse: 0.684946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3951. Best iteration is:\n",
      "\t[3951]\tvalid_set's rmse: 0.684433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3950]\tvalid_set's rmse: 0.684446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.6934\t = Validation score   (root_mean_squared_error)\n",
      "\t5491.18s\t = Training   runtime\n",
      "\t568.82s\t = Validation runtime\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 117.41s of the 3714.32s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 35. Best iteration is:\n",
      "\t[35]\tvalid_set's rmse: 0.796226\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 101.64s of the 3698.55s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 8\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 163 due to low memory. Expected memory usage reduced from 27.48% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 1676.5s to train, which exceeds the maximum time limit of 101.6s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 58.45s of the 3655.35s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tMemory not enough to fit CatBoostModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 4, 'task_type': 'GPU'}\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0820758\ttest: 1.0839185\tbest: 1.0839185 (0)\ttotal: 145ms\tremaining: 145ms\n",
      "1:\tlearn: 1.0619764\ttest: 1.0638102\tbest: 1.0638102 (1)\ttotal: 276ms\tremaining: 0us\n",
      "bestTest = 1.063810194\n",
      "bestIteration = 1\n",
      "0:\tlearn: 1.0820758\ttest: 1.0839185\tbest: 1.0839185 (0)\ttotal: 111ms\tremaining: 111ms\n",
      "1:\tlearn: 1.0619764\ttest: 1.0638102\tbest: 1.0638102 (1)\ttotal: 221ms\tremaining: 0us\n",
      "bestTest = 1.063810194\n",
      "bestIteration = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 49.13s of the 3646.04s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 8\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 131 due to low memory. Expected memory usage reduced from 34.18% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 708.7s to train, which exceeds the maximum time limit of 49.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 25.42s of the 3622.32s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tMemory not enough to fit NNFastAiTabularModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 0/0 categorical features\n",
      "Using 8 cont features\n",
      "Automated batch size selection: 512\n",
      "TabularModel(\n",
      "  (embeds): ModuleList()\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=8, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 11.99s of the 3608.89s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tMemory not enough to fit XGBoostModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.07109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ran out of time, early stopping on iteration 0. Best iteration is: \t[0]\t1.071085\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Not enough time left to finish repeated k-fold bagging, stopping early ...\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 718.84s of the 3595.61s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Ensemble size: 89\n",
      "Ensemble weights: \n",
      "[0.         0.91011236 0.08988764]\n",
      "\t29.53s\t= Estimated out-of-fold prediction time...\n",
      "Saving agModels-regression_Best_Quality/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving agModels-regression_Best_Quality/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.2481\t = Validation score   (root_mean_squared_error)\n",
      "\t118.1s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_fit': {'num_gpus': 1}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3476.92s of the 3476.18s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.22965\n",
      "[100]\tvalid_set's rmse: 0.195478\n",
      "[150]\tvalid_set's rmse: 0.189276\n",
      "[200]\tvalid_set's rmse: 0.186157\n",
      "[250]\tvalid_set's rmse: 0.183727\n",
      "[300]\tvalid_set's rmse: 0.181828\n",
      "[350]\tvalid_set's rmse: 0.180499\n",
      "[400]\tvalid_set's rmse: 0.17934\n",
      "[450]\tvalid_set's rmse: 0.178395\n",
      "[500]\tvalid_set's rmse: 0.177623\n",
      "[550]\tvalid_set's rmse: 0.176709\n",
      "[600]\tvalid_set's rmse: 0.176096\n",
      "[650]\tvalid_set's rmse: 0.175492\n",
      "[700]\tvalid_set's rmse: 0.174713\n",
      "[750]\tvalid_set's rmse: 0.174213\n",
      "[800]\tvalid_set's rmse: 0.173702\n",
      "[850]\tvalid_set's rmse: 0.173184\n",
      "[900]\tvalid_set's rmse: 0.172713\n",
      "[950]\tvalid_set's rmse: 0.172226\n",
      "[1000]\tvalid_set's rmse: 0.171848\n",
      "[1050]\tvalid_set's rmse: 0.171538\n",
      "[1100]\tvalid_set's rmse: 0.171162\n",
      "[1150]\tvalid_set's rmse: 0.170807\n",
      "[1200]\tvalid_set's rmse: 0.170451\n",
      "[1250]\tvalid_set's rmse: 0.170177\n",
      "[1300]\tvalid_set's rmse: 0.169868\n",
      "[1350]\tvalid_set's rmse: 0.169569\n",
      "[1400]\tvalid_set's rmse: 0.169331\n",
      "[1450]\tvalid_set's rmse: 0.169069\n",
      "[1500]\tvalid_set's rmse: 0.168837\n",
      "[1550]\tvalid_set's rmse: 0.168548\n",
      "[1600]\tvalid_set's rmse: 0.168299\n",
      "[1650]\tvalid_set's rmse: 0.168101\n",
      "[1700]\tvalid_set's rmse: 0.167891\n",
      "[1750]\tvalid_set's rmse: 0.167663\n",
      "[1800]\tvalid_set's rmse: 0.167454\n",
      "[1850]\tvalid_set's rmse: 0.167292\n",
      "[1900]\tvalid_set's rmse: 0.167117\n",
      "[1950]\tvalid_set's rmse: 0.166889\n",
      "[2000]\tvalid_set's rmse: 0.166673\n",
      "[2050]\tvalid_set's rmse: 0.166516\n",
      "[2100]\tvalid_set's rmse: 0.166343\n",
      "[2150]\tvalid_set's rmse: 0.166196\n",
      "[2200]\tvalid_set's rmse: 0.16606\n",
      "[2250]\tvalid_set's rmse: 0.165911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2255. Best iteration is:\n",
      "\t[2255]\tvalid_set's rmse: 0.165903\n",
      "\tFitting S1F2 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.231616\n",
      "[100]\tvalid_set's rmse: 0.197641\n",
      "[150]\tvalid_set's rmse: 0.191865\n",
      "[200]\tvalid_set's rmse: 0.18848\n",
      "[250]\tvalid_set's rmse: 0.186155\n",
      "[300]\tvalid_set's rmse: 0.184421\n",
      "[350]\tvalid_set's rmse: 0.182829\n",
      "[400]\tvalid_set's rmse: 0.181662\n",
      "[450]\tvalid_set's rmse: 0.180566\n",
      "[500]\tvalid_set's rmse: 0.179749\n",
      "[550]\tvalid_set's rmse: 0.178879\n",
      "[600]\tvalid_set's rmse: 0.178137\n",
      "[650]\tvalid_set's rmse: 0.177464\n",
      "[700]\tvalid_set's rmse: 0.176891\n",
      "[750]\tvalid_set's rmse: 0.176367\n",
      "[800]\tvalid_set's rmse: 0.175844\n",
      "[850]\tvalid_set's rmse: 0.175355\n",
      "[900]\tvalid_set's rmse: 0.174935\n",
      "[950]\tvalid_set's rmse: 0.174497\n",
      "[1000]\tvalid_set's rmse: 0.174126\n",
      "[1050]\tvalid_set's rmse: 0.173776\n",
      "[1100]\tvalid_set's rmse: 0.173501\n",
      "[1150]\tvalid_set's rmse: 0.173188\n",
      "[1200]\tvalid_set's rmse: 0.172913\n",
      "[1250]\tvalid_set's rmse: 0.17252\n",
      "[1300]\tvalid_set's rmse: 0.172261\n",
      "[1350]\tvalid_set's rmse: 0.171997\n",
      "[1400]\tvalid_set's rmse: 0.171772\n",
      "[1450]\tvalid_set's rmse: 0.171471\n",
      "[1500]\tvalid_set's rmse: 0.17126\n",
      "[1550]\tvalid_set's rmse: 0.171023\n",
      "[1600]\tvalid_set's rmse: 0.170802\n",
      "[1650]\tvalid_set's rmse: 0.170573\n",
      "[1700]\tvalid_set's rmse: 0.170369\n",
      "[1750]\tvalid_set's rmse: 0.17015\n",
      "[1800]\tvalid_set's rmse: 0.169962\n",
      "[1850]\tvalid_set's rmse: 0.16976\n",
      "[1900]\tvalid_set's rmse: 0.169565\n",
      "[1950]\tvalid_set's rmse: 0.169394\n",
      "[2000]\tvalid_set's rmse: 0.169203\n",
      "[2050]\tvalid_set's rmse: 0.169022\n",
      "[2100]\tvalid_set's rmse: 0.168886\n",
      "[2150]\tvalid_set's rmse: 0.168748\n",
      "[2200]\tvalid_set's rmse: 0.168539\n",
      "[2250]\tvalid_set's rmse: 0.168317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2256. Best iteration is:\n",
      "\t[2256]\tvalid_set's rmse: 0.168296\n",
      "\tFitting S1F3 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.22933\n",
      "[100]\tvalid_set's rmse: 0.195004\n",
      "[150]\tvalid_set's rmse: 0.189048\n",
      "[200]\tvalid_set's rmse: 0.185743\n",
      "[250]\tvalid_set's rmse: 0.183228\n",
      "[300]\tvalid_set's rmse: 0.181398\n",
      "[350]\tvalid_set's rmse: 0.18004\n",
      "[400]\tvalid_set's rmse: 0.178838\n",
      "[450]\tvalid_set's rmse: 0.177703\n",
      "[500]\tvalid_set's rmse: 0.1769\n",
      "[550]\tvalid_set's rmse: 0.176146\n",
      "[600]\tvalid_set's rmse: 0.175459\n",
      "[650]\tvalid_set's rmse: 0.174748\n",
      "[700]\tvalid_set's rmse: 0.174234\n",
      "[750]\tvalid_set's rmse: 0.173729\n",
      "[800]\tvalid_set's rmse: 0.17325\n",
      "[850]\tvalid_set's rmse: 0.172831\n",
      "[900]\tvalid_set's rmse: 0.172348\n",
      "[950]\tvalid_set's rmse: 0.171927\n",
      "[1000]\tvalid_set's rmse: 0.171554\n",
      "[1050]\tvalid_set's rmse: 0.171226\n",
      "[1100]\tvalid_set's rmse: 0.170911\n",
      "[1150]\tvalid_set's rmse: 0.170692\n",
      "[1200]\tvalid_set's rmse: 0.170423\n",
      "[1250]\tvalid_set's rmse: 0.170131\n",
      "[1300]\tvalid_set's rmse: 0.169875\n",
      "[1350]\tvalid_set's rmse: 0.169595\n",
      "[1400]\tvalid_set's rmse: 0.169362\n",
      "[2100]\tvalid_set's rmse: 0.166637\n",
      "[2150]\tvalid_set's rmse: 0.166492\n",
      "[2200]\tvalid_set's rmse: 0.166303\n",
      "[2250]\tvalid_set's rmse: 0.166147\n",
      "[2300]\tvalid_set's rmse: 0.165997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2317. Best iteration is:\n",
      "\t[2317]\tvalid_set's rmse: 0.165955\n",
      "\tFitting S1F4 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.230497\n",
      "[100]\tvalid_set's rmse: 0.195973\n",
      "[150]\tvalid_set's rmse: 0.189973\n",
      "[200]\tvalid_set's rmse: 0.186394\n",
      "[250]\tvalid_set's rmse: 0.18448\n",
      "[300]\tvalid_set's rmse: 0.182674\n",
      "[350]\tvalid_set's rmse: 0.181266\n",
      "[400]\tvalid_set's rmse: 0.180146\n",
      "[450]\tvalid_set's rmse: 0.17912\n",
      "[500]\tvalid_set's rmse: 0.178328\n",
      "[550]\tvalid_set's rmse: 0.177692\n",
      "[600]\tvalid_set's rmse: 0.176995\n",
      "[650]\tvalid_set's rmse: 0.17637\n",
      "[700]\tvalid_set's rmse: 0.175823\n",
      "[750]\tvalid_set's rmse: 0.17533\n",
      "[800]\tvalid_set's rmse: 0.174903\n",
      "[850]\tvalid_set's rmse: 0.174435\n",
      "[900]\tvalid_set's rmse: 0.174013\n",
      "[950]\tvalid_set's rmse: 0.173679\n",
      "[1000]\tvalid_set's rmse: 0.173293\n",
      "[1050]\tvalid_set's rmse: 0.172895\n",
      "[1100]\tvalid_set's rmse: 0.17255\n",
      "[1150]\tvalid_set's rmse: 0.172174\n",
      "[1200]\tvalid_set's rmse: 0.171889\n",
      "[1250]\tvalid_set's rmse: 0.171647\n",
      "[1300]\tvalid_set's rmse: 0.171335\n",
      "[1350]\tvalid_set's rmse: 0.171103\n",
      "[1400]\tvalid_set's rmse: 0.170854\n",
      "[1450]\tvalid_set's rmse: 0.170598\n",
      "[1500]\tvalid_set's rmse: 0.170373\n",
      "[1550]\tvalid_set's rmse: 0.170149\n",
      "[1600]\tvalid_set's rmse: 0.169955\n",
      "[1650]\tvalid_set's rmse: 0.169768\n",
      "[1700]\tvalid_set's rmse: 0.16953\n",
      "[1750]\tvalid_set's rmse: 0.169334\n",
      "[1800]\tvalid_set's rmse: 0.169161\n",
      "[1850]\tvalid_set's rmse: 0.16894\n",
      "[1900]\tvalid_set's rmse: 0.16875\n",
      "[1950]\tvalid_set's rmse: 0.168584\n",
      "[2000]\tvalid_set's rmse: 0.168389\n",
      "[2050]\tvalid_set's rmse: 0.168243\n",
      "[2100]\tvalid_set's rmse: 0.168074\n",
      "[2150]\tvalid_set's rmse: 0.167891\n",
      "[2200]\tvalid_set's rmse: 0.167762\n",
      "[2250]\tvalid_set's rmse: 0.167607\n",
      "[2300]\tvalid_set's rmse: 0.167481\n",
      "[2350]\tvalid_set's rmse: 0.167331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2400. Best iteration is:\n",
      "\t[2400]\tvalid_set's rmse: 0.167152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400]\tvalid_set's rmse: 0.167152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting S1F5 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.227953\n",
      "[100]\tvalid_set's rmse: 0.194076\n",
      "[150]\tvalid_set's rmse: 0.188406\n",
      "[200]\tvalid_set's rmse: 0.185293\n",
      "[250]\tvalid_set's rmse: 0.183354\n",
      "[300]\tvalid_set's rmse: 0.181725\n",
      "[350]\tvalid_set's rmse: 0.180228\n",
      "[400]\tvalid_set's rmse: 0.179255\n",
      "[450]\tvalid_set's rmse: 0.178205\n",
      "[500]\tvalid_set's rmse: 0.177431\n",
      "[550]\tvalid_set's rmse: 0.176747\n",
      "[600]\tvalid_set's rmse: 0.176179\n",
      "[650]\tvalid_set's rmse: 0.175555\n",
      "[700]\tvalid_set's rmse: 0.174985\n",
      "[750]\tvalid_set's rmse: 0.174544\n",
      "[800]\tvalid_set's rmse: 0.173954\n",
      "[850]\tvalid_set's rmse: 0.17367\n",
      "[900]\tvalid_set's rmse: 0.173311\n",
      "[950]\tvalid_set's rmse: 0.172921\n",
      "[1000]\tvalid_set's rmse: 0.172516\n",
      "[1050]\tvalid_set's rmse: 0.172199\n",
      "[1100]\tvalid_set's rmse: 0.171868\n",
      "[1150]\tvalid_set's rmse: 0.171539\n",
      "[1200]\tvalid_set's rmse: 0.171227\n",
      "[1250]\tvalid_set's rmse: 0.170942\n",
      "[1300]\tvalid_set's rmse: 0.170694\n",
      "[1350]\tvalid_set's rmse: 0.170435\n",
      "[1400]\tvalid_set's rmse: 0.170163\n",
      "[1450]\tvalid_set's rmse: 0.169894\n",
      "[1500]\tvalid_set's rmse: 0.169693\n",
      "[1550]\tvalid_set's rmse: 0.16944\n",
      "[1600]\tvalid_set's rmse: 0.169239\n",
      "[1650]\tvalid_set's rmse: 0.169037\n",
      "[1700]\tvalid_set's rmse: 0.168848\n",
      "[1750]\tvalid_set's rmse: 0.168663\n",
      "[1800]\tvalid_set's rmse: 0.168491\n",
      "[1850]\tvalid_set's rmse: 0.168295\n",
      "[1900]\tvalid_set's rmse: 0.168096\n",
      "[1950]\tvalid_set's rmse: 0.167877\n",
      "[2000]\tvalid_set's rmse: 0.167696\n",
      "[2050]\tvalid_set's rmse: 0.16751\n",
      "[2100]\tvalid_set's rmse: 0.167319\n",
      "[2150]\tvalid_set's rmse: 0.167145\n",
      "[2200]\tvalid_set's rmse: 0.166961\n",
      "[2250]\tvalid_set's rmse: 0.166821\n",
      "[2300]\tvalid_set's rmse: 0.166686\n",
      "[2350]\tvalid_set's rmse: 0.166558\n",
      "[2400]\tvalid_set's rmse: 0.166435\n",
      "[2450]\tvalid_set's rmse: 0.166304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2477. Best iteration is:\n",
      "\t[2477]\tvalid_set's rmse: 0.166235\n",
      "\tFitting S1F6 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.227536\n",
      "[100]\tvalid_set's rmse: 0.19432\n",
      "[150]\tvalid_set's rmse: 0.189144\n",
      "[200]\tvalid_set's rmse: 0.186018\n",
      "[250]\tvalid_set's rmse: 0.183915\n",
      "[300]\tvalid_set's rmse: 0.182413\n",
      "[350]\tvalid_set's rmse: 0.181054\n",
      "[400]\tvalid_set's rmse: 0.179987\n",
      "[450]\tvalid_set's rmse: 0.178895\n",
      "[500]\tvalid_set's rmse: 0.17807\n",
      "[550]\tvalid_set's rmse: 0.177244\n",
      "[600]\tvalid_set's rmse: 0.176508\n",
      "[650]\tvalid_set's rmse: 0.17591\n",
      "[700]\tvalid_set's rmse: 0.175263\n",
      "[750]\tvalid_set's rmse: 0.174773\n",
      "[800]\tvalid_set's rmse: 0.174198\n",
      "[850]\tvalid_set's rmse: 0.173688\n",
      "[900]\tvalid_set's rmse: 0.173324\n",
      "[950]\tvalid_set's rmse: 0.172878\n",
      "[1000]\tvalid_set's rmse: 0.172437\n",
      "[1050]\tvalid_set's rmse: 0.172066\n",
      "[1100]\tvalid_set's rmse: 0.171675\n",
      "[1150]\tvalid_set's rmse: 0.171351\n",
      "[1200]\tvalid_set's rmse: 0.171062\n",
      "[1250]\tvalid_set's rmse: 0.170794\n",
      "[1300]\tvalid_set's rmse: 0.17055\n",
      "[1350]\tvalid_set's rmse: 0.170229\n",
      "[1400]\tvalid_set's rmse: 0.169974\n",
      "[1450]\tvalid_set's rmse: 0.169716\n",
      "[1500]\tvalid_set's rmse: 0.169476\n",
      "[1550]\tvalid_set's rmse: 0.169251\n",
      "[1600]\tvalid_set's rmse: 0.169036\n",
      "[1650]\tvalid_set's rmse: 0.168834\n",
      "[1700]\tvalid_set's rmse: 0.168649\n",
      "[1750]\tvalid_set's rmse: 0.168446\n",
      "[1800]\tvalid_set's rmse: 0.168212\n",
      "[1850]\tvalid_set's rmse: 0.167996\n",
      "[1900]\tvalid_set's rmse: 0.167844\n",
      "[1950]\tvalid_set's rmse: 0.167661\n",
      "[2000]\tvalid_set's rmse: 0.167478\n",
      "[2050]\tvalid_set's rmse: 0.167288\n",
      "[2100]\tvalid_set's rmse: 0.167137\n",
      "[2150]\tvalid_set's rmse: 0.166987\n",
      "[2200]\tvalid_set's rmse: 0.166839\n",
      "[2250]\tvalid_set's rmse: 0.166667\n",
      "[2300]\tvalid_set's rmse: 0.166531\n",
      "[2350]\tvalid_set's rmse: 0.166353\n",
      "[2400]\tvalid_set's rmse: 0.166231\n",
      "[2450]\tvalid_set's rmse: 0.166098\n",
      "[2500]\tvalid_set's rmse: 0.165979\n",
      "[2550]\tvalid_set's rmse: 0.165841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2592. Best iteration is:\n",
      "\t[2592]\tvalid_set's rmse: 0.165737\n",
      "\tFitting S1F7 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.228569\n",
      "[100]\tvalid_set's rmse: 0.193935\n",
      "[150]\tvalid_set's rmse: 0.188333\n",
      "[200]\tvalid_set's rmse: 0.185289\n",
      "[250]\tvalid_set's rmse: 0.183103\n",
      "[300]\tvalid_set's rmse: 0.181412\n",
      "[350]\tvalid_set's rmse: 0.179978\n",
      "[400]\tvalid_set's rmse: 0.178956\n",
      "[450]\tvalid_set's rmse: 0.177997\n",
      "[500]\tvalid_set's rmse: 0.177091\n",
      "[550]\tvalid_set's rmse: 0.176363\n",
      "[600]\tvalid_set's rmse: 0.175691\n",
      "[650]\tvalid_set's rmse: 0.175016\n",
      "[700]\tvalid_set's rmse: 0.17448\n",
      "[750]\tvalid_set's rmse: 0.173928\n",
      "[800]\tvalid_set's rmse: 0.173313\n",
      "[850]\tvalid_set's rmse: 0.17289\n",
      "[900]\tvalid_set's rmse: 0.172464\n",
      "[950]\tvalid_set's rmse: 0.172042\n",
      "[1000]\tvalid_set's rmse: 0.171707\n",
      "[1050]\tvalid_set's rmse: 0.171339\n",
      "[1100]\tvalid_set's rmse: 0.17105\n",
      "[1150]\tvalid_set's rmse: 0.170702\n",
      "[1200]\tvalid_set's rmse: 0.170401\n",
      "[1250]\tvalid_set's rmse: 0.170151\n",
      "[1300]\tvalid_set's rmse: 0.169891\n",
      "[1350]\tvalid_set's rmse: 0.169631\n",
      "[1400]\tvalid_set's rmse: 0.16938\n",
      "[1450]\tvalid_set's rmse: 0.1691\n",
      "[1500]\tvalid_set's rmse: 0.168857\n",
      "[1550]\tvalid_set's rmse: 0.168666\n",
      "[1600]\tvalid_set's rmse: 0.168486\n",
      "[1650]\tvalid_set's rmse: 0.168279\n",
      "[1700]\tvalid_set's rmse: 0.168\n",
      "[1750]\tvalid_set's rmse: 0.167842\n",
      "[1800]\tvalid_set's rmse: 0.167667\n",
      "[1850]\tvalid_set's rmse: 0.167491\n",
      "[1900]\tvalid_set's rmse: 0.167316\n",
      "[1950]\tvalid_set's rmse: 0.167088\n",
      "[2000]\tvalid_set's rmse: 0.166896\n",
      "[2050]\tvalid_set's rmse: 0.166749\n",
      "[2100]\tvalid_set's rmse: 0.166579\n",
      "[2150]\tvalid_set's rmse: 0.166405\n",
      "[2200]\tvalid_set's rmse: 0.166253\n",
      "[2250]\tvalid_set's rmse: 0.166065\n",
      "[2300]\tvalid_set's rmse: 0.165953\n",
      "[2350]\tvalid_set's rmse: 0.165823\n",
      "[2400]\tvalid_set's rmse: 0.165698\n",
      "[2450]\tvalid_set's rmse: 0.165571\n",
      "[2500]\tvalid_set's rmse: 0.165428\n",
      "[2550]\tvalid_set's rmse: 0.165296\n",
      "[2600]\tvalid_set's rmse: 0.165181\n",
      "[2650]\tvalid_set's rmse: 0.165056\n",
      "[2700]\tvalid_set's rmse: 0.164973\n",
      "[2750]\tvalid_set's rmse: 0.164844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2757. Best iteration is:\n",
      "\t[2757]\tvalid_set's rmse: 0.164827\n",
      "\tFitting S1F8 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True, 'device': 'gpu'}\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 0.228983\n",
      "[100]\tvalid_set's rmse: 0.195154\n",
      "[150]\tvalid_set's rmse: 0.189461\n",
      "[200]\tvalid_set's rmse: 0.186249\n",
      "[250]\tvalid_set's rmse: 0.184022\n",
      "[300]\tvalid_set's rmse: 0.182406\n",
      "[350]\tvalid_set's rmse: 0.181042\n",
      "[400]\tvalid_set's rmse: 0.179858\n",
      "[450]\tvalid_set's rmse: 0.178911\n",
      "[500]\tvalid_set's rmse: 0.177877\n",
      "[550]\tvalid_set's rmse: 0.177208\n",
      "[600]\tvalid_set's rmse: 0.176524\n",
      "[650]\tvalid_set's rmse: 0.175859\n",
      "[700]\tvalid_set's rmse: 0.17532\n",
      "[750]\tvalid_set's rmse: 0.174791\n",
      "[800]\tvalid_set's rmse: 0.174285\n",
      "[850]\tvalid_set's rmse: 0.173773\n",
      "[900]\tvalid_set's rmse: 0.173351\n",
      "[950]\tvalid_set's rmse: 0.172934\n",
      "[1000]\tvalid_set's rmse: 0.172574\n",
      "[1050]\tvalid_set's rmse: 0.172296\n",
      "[1100]\tvalid_set's rmse: 0.171963\n",
      "[1150]\tvalid_set's rmse: 0.171663\n",
      "[1200]\tvalid_set's rmse: 0.17133\n",
      "[1250]\tvalid_set's rmse: 0.171057\n",
      "[1300]\tvalid_set's rmse: 0.170784\n",
      "[1350]\tvalid_set's rmse: 0.170522\n",
      "[1400]\tvalid_set's rmse: 0.170274\n",
      "[1450]\tvalid_set's rmse: 0.170039\n",
      "[1500]\tvalid_set's rmse: 0.169824\n",
      "[1550]\tvalid_set's rmse: 0.169575\n",
      "[1600]\tvalid_set's rmse: 0.16938\n",
      "[1650]\tvalid_set's rmse: 0.169143\n",
      "[1700]\tvalid_set's rmse: 0.168951\n",
      "[1750]\tvalid_set's rmse: 0.168756\n",
      "[1800]\tvalid_set's rmse: 0.168539\n",
      "[1850]\tvalid_set's rmse: 0.168375\n",
      "[1900]\tvalid_set's rmse: 0.168211\n",
      "[1950]\tvalid_set's rmse: 0.168051\n",
      "[2000]\tvalid_set's rmse: 0.167872\n",
      "[2050]\tvalid_set's rmse: 0.167723\n",
      "[2100]\tvalid_set's rmse: 0.167531\n",
      "[2150]\tvalid_set's rmse: 0.167363\n",
      "[2200]\tvalid_set's rmse: 0.167211\n",
      "[2250]\tvalid_set's rmse: 0.167038\n",
      "[2300]\tvalid_set's rmse: 0.166888\n",
      "[2350]\tvalid_set's rmse: 0.166734\n",
      "[2400]\tvalid_set's rmse: 0.16661\n",
      "[2450]\tvalid_set's rmse: 0.166481\n",
      "[2500]\tvalid_set's rmse: 0.166341\n",
      "[2550]\tvalid_set's rmse: 0.16619\n",
      "[2600]\tvalid_set's rmse: 0.166034\n",
      "[2650]\tvalid_set's rmse: 0.165871\n",
      "[2700]\tvalid_set's rmse: 0.165743\n",
      "[2750]\tvalid_set's rmse: 0.165615\n",
      "[2800]\tvalid_set's rmse: 0.165515\n",
      "[2850]\tvalid_set's rmse: 0.165409\n",
      "[2900]\tvalid_set's rmse: 0.16531\n",
      "[2950]\tvalid_set's rmse: 0.165192\n",
      "[3000]\tvalid_set's rmse: 0.165083\n",
      "[3050]\tvalid_set's rmse: 0.164934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3073. Best iteration is:\n",
      "\t[3073]\tvalid_set's rmse: 0.164893\n",
      "Saving agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.1661\t = Validation score   (root_mean_squared_error)\n",
      "\t3083.95s\t = Training   runtime\n",
      "\t326.52s\t = Validation runtime\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 60.39s of the 60.05s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 4\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'device': 'gpu'}\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 8. Best iteration is:\n",
      "\t[8]\tvalid_set's rmse: 0.745231\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L2.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 48.31s of the 47.96s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 1, 'num_cpus': 8\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 145 due to low memory. Expected memory usage reduced from 30.96% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 3462.6s to train, which exceeds the maximum time limit of 48.3s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping ExtraTreesMSE_BAG_L2 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Not enough time left to finish repeated k-fold bagging, stopping early ...\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -51.83s of remaining time.\n",
      "Saving agModels-regression_Best_Quality/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "\t17.07s\t= Estimated out-of-fold prediction time...\n",
      "Saving agModels-regression_Best_Quality/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving agModels-regression_Best_Quality/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.1661\t = Validation score   (root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 10853.44s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Loading: agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Saving agModels-regression_Best_Quality/models/trainer.pkl\n",
      "Saving agModels-regression_Best_Quality/learner.pkl\n",
      "Saving agModels-regression_Best_Quality/predictor.pkl\n",
      "Saving agModels-regression_Best_Quality/__version__ with contents \"0.4.1b20220417\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-regression_Best_Quality/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-regression_Best_Quality'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label=target, eval_metric = 'rmse',path=save_path,verbosity=3).fit(train_data, \n",
    "                                                               time_limit=10800,\n",
    "                                                               presets = 'best_quality' ,                                \n",
    "                                                               ag_args_fit={'num_gpus': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a84b8999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L3'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab55b7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior_ledger_sequence</th>\n",
       "      <th>prior_operation_count</th>\n",
       "      <th>prior_max_fee_charged</th>\n",
       "      <th>prior_min_fee_charged</th>\n",
       "      <th>prior_avg_fee_charged</th>\n",
       "      <th>transaction_operation_count</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>final_fee_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40372943</td>\n",
       "      <td>972</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>183.742911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40370144</td>\n",
       "      <td>968</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>218.018018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65272999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40367230</td>\n",
       "      <td>953</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>202.335456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40368696</td>\n",
       "      <td>955</td>\n",
       "      <td>9000</td>\n",
       "      <td>100</td>\n",
       "      <td>256.032172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40367824</td>\n",
       "      <td>1000</td>\n",
       "      <td>860000</td>\n",
       "      <td>20000</td>\n",
       "      <td>25252.525253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500142</th>\n",
       "      <td>40372471</td>\n",
       "      <td>1000</td>\n",
       "      <td>90000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1782.531194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500143</th>\n",
       "      <td>40372725</td>\n",
       "      <td>998</td>\n",
       "      <td>5000</td>\n",
       "      <td>100</td>\n",
       "      <td>143.390805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500144</th>\n",
       "      <td>40373348</td>\n",
       "      <td>1000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>170.648464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500145</th>\n",
       "      <td>40373289</td>\n",
       "      <td>1000</td>\n",
       "      <td>100000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2012.072435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500146</th>\n",
       "      <td>40373687</td>\n",
       "      <td>966</td>\n",
       "      <td>3200</td>\n",
       "      <td>100</td>\n",
       "      <td>151.173709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500147 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior_ledger_sequence  prior_operation_count  prior_max_fee_charged  \\\n",
       "0                     40372943                    972                  10000   \n",
       "1                     40370144                    968                  10000   \n",
       "2                     40367230                    953                  10000   \n",
       "3                     40368696                    955                   9000   \n",
       "4                     40367824                   1000                 860000   \n",
       "...                        ...                    ...                    ...   \n",
       "3500142               40372471                   1000                  90000   \n",
       "3500143               40372725                    998                   5000   \n",
       "3500144               40373348                   1000                  10000   \n",
       "3500145               40373289                   1000                 100000   \n",
       "3500146               40373687                    966                   3200   \n",
       "\n",
       "         prior_min_fee_charged  prior_avg_fee_charged  \\\n",
       "0                          100             183.742911   \n",
       "1                          100             218.018018   \n",
       "2                          100             202.335456   \n",
       "3                          100             256.032172   \n",
       "4                        20000           25252.525253   \n",
       "...                        ...                    ...   \n",
       "3500142                   1000            1782.531194   \n",
       "3500143                    100             143.390805   \n",
       "3500144                    100             170.648464   \n",
       "3500145                   1000            2012.072435   \n",
       "3500146                    100             151.173709   \n",
       "\n",
       "         transaction_operation_count  sponsor  final_fee_bid  \n",
       "0                                  1        0          821.0  \n",
       "1                                  1        0     65272999.0  \n",
       "2                                  1        0     10000000.0  \n",
       "3                                  1        0          500.0  \n",
       "4                                  1        0      9000000.0  \n",
       "...                              ...      ...            ...  \n",
       "3500142                            1        0       150000.0  \n",
       "3500143                            1        0       150000.0  \n",
       "3500144                            1        0       150000.0  \n",
       "3500145                            1        0       150000.0  \n",
       "3500146                            1        0       150000.0  \n",
       "\n",
       "[3500147 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_features = [\"prior_ledger_sequence\",  \n",
    "            \"prior_operation_count\",\n",
    "            \"prior_max_fee_charged\",\n",
    "            \"prior_min_fee_charged\",\n",
    "            \"prior_avg_fee_charged\",\n",
    "            \"transaction_operation_count\",\n",
    "            \"sponsor\",\n",
    "            \"final_fee_bid\"]\n",
    "\n",
    "\n",
    "test_df[only_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca38753b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior_ledger_sequence</th>\n",
       "      <th>prior_operation_count</th>\n",
       "      <th>prior_max_fee_charged</th>\n",
       "      <th>prior_min_fee_charged</th>\n",
       "      <th>prior_avg_fee_charged</th>\n",
       "      <th>transaction_operation_count</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>final_fee_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40372943</td>\n",
       "      <td>972</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>183.742911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40370144</td>\n",
       "      <td>968</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>218.018018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65272999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40367230</td>\n",
       "      <td>953</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>202.335456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40368696</td>\n",
       "      <td>955</td>\n",
       "      <td>9000</td>\n",
       "      <td>100</td>\n",
       "      <td>256.032172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40367824</td>\n",
       "      <td>1000</td>\n",
       "      <td>860000</td>\n",
       "      <td>20000</td>\n",
       "      <td>25252.525253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior_ledger_sequence  prior_operation_count  prior_max_fee_charged  \\\n",
       "0               40372943                    972                  10000   \n",
       "1               40370144                    968                  10000   \n",
       "2               40367230                    953                  10000   \n",
       "3               40368696                    955                   9000   \n",
       "4               40367824                   1000                 860000   \n",
       "\n",
       "   prior_min_fee_charged  prior_avg_fee_charged  transaction_operation_count  \\\n",
       "0                    100             183.742911                            1   \n",
       "1                    100             218.018018                            1   \n",
       "2                    100             202.335456                            1   \n",
       "3                    100             256.032172                            1   \n",
       "4                  20000           25252.525253                            1   \n",
       "\n",
       "   sponsor  final_fee_bid  \n",
       "0        0          821.0  \n",
       "1        0     65272999.0  \n",
       "2        0     10000000.0  \n",
       "3        0          500.0  \n",
       "4        0      9000000.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(test_df[only_features])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f458f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNeighborsUnif_BAG_L1',\n",
       " 'KNeighborsDist_BAG_L1',\n",
       " 'LightGBMXT_BAG_L1',\n",
       " 'WeightedEnsemble_L2',\n",
       " 'LightGBMXT_BAG_L2',\n",
       " 'WeightedEnsemble_L3']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = predictor.get_model_names()\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22d3c27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/model.pkl\n"
     ]
    }
   ],
   "source": [
    "y_pred_KNeighborsUnif_BAG_L1 = predictor.predict(test_data, model=all_models[0])\n",
    "\n",
    "y_pred_KNeighborsDist_BAG_L1= predictor.predict(test_data, model=all_models[1])\n",
    "\n",
    "y_pred_LightGBMXT_BAG_L1 = predictor.predict(test_data, model=all_models[2])\n",
    "\n",
    "y_pred_WeightedEnsemble_L2 = predictor.predict(test_data, model=all_models[3])\n",
    "\n",
    "y_pred_LightGBMXT_BAG_L2 = predictor.predict(test_data, model=all_models[4])\n",
    "\n",
    "y_pred_WeightedEnsemble_L3 = predictor.predict(test_data, model=all_models[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c00e4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df = pd.DataFrame()\n",
    "\n",
    "final_pred_df['transaction_id'] = test_df['transaction_id']\n",
    "final_pred_df['predicted_fee_1'] = y_pred_KNeighborsUnif_BAG_L1\n",
    "final_pred_df['predicted_fee_2'] = y_pred_KNeighborsDist_BAG_L1\n",
    "final_pred_df['predicted_fee_3'] = y_pred_LightGBMXT_BAG_L1\n",
    "final_pred_df['predicted_fee_4'] = y_pred_WeightedEnsemble_L2\n",
    "final_pred_df['predicted_fee_5'] = y_pred_LightGBMXT_BAG_L2\n",
    "final_pred_df['predicted_fee_6'] = y_pred_WeightedEnsemble_L3\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5aa9b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df[\"predicted_fee_1\"] = np.exp(final_pred_df[\"predicted_fee_1\"])*100\n",
    "final_pred_df[\"predicted_fee_2\"] = np.exp(final_pred_df[\"predicted_fee_2\"])*100\n",
    "final_pred_df[\"predicted_fee_3\"] = np.exp(final_pred_df[\"predicted_fee_3\"])*100\n",
    "final_pred_df[\"predicted_fee_4\"] = np.exp(final_pred_df[\"predicted_fee_4\"])*100\n",
    "final_pred_df[\"predicted_fee_5\"] = np.exp(final_pred_df[\"predicted_fee_5\"])*100\n",
    "final_pred_df[\"predicted_fee_6\"] = np.exp(final_pred_df[\"predicted_fee_6\"])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a84447cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame()\n",
    "submission_df['transaction_id'] = final_pred_df['transaction_id']\n",
    "submission_df['predicted_fee']= final_pred_df['predicted_fee_6']\n",
    "\n",
    "submission_df.to_csv(\"WeightedEnsemble_L3.csv\",index=False)\n",
    "\n",
    "\n",
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57e5d9",
   "metadata": {},
   "source": [
    "### Take Mean of all Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe8b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b412cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df[\"Ensemble_Mean\"] = final_pred_df.iloc[:,1:].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d290cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame()\n",
    "submission_df['transaction_id'] = final_pred_df['transaction_id']\n",
    "submission_df['predicted_fee']= final_pred_df['Ensemble_Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afbae323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>predicted_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173400474125250560</td>\n",
       "      <td>98.791954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173388452511141888</td>\n",
       "      <td>101.425514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173375936976945152</td>\n",
       "      <td>114.737022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173382233397809152</td>\n",
       "      <td>117.416771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173378488186241024</td>\n",
       "      <td>319.793549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500142</th>\n",
       "      <td>173398446900080640</td>\n",
       "      <td>846.284729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500143</th>\n",
       "      <td>173399537822896128</td>\n",
       "      <td>227.922485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500144</th>\n",
       "      <td>173402213585080320</td>\n",
       "      <td>239.218277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500145</th>\n",
       "      <td>173401960184356864</td>\n",
       "      <td>271.998993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500146</th>\n",
       "      <td>173403669580005376</td>\n",
       "      <td>197.939407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500147 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             transaction_id  predicted_fee\n",
       "0        173400474125250560      98.791954\n",
       "1        173388452511141888     101.425514\n",
       "2        173375936976945152     114.737022\n",
       "3        173382233397809152     117.416771\n",
       "4        173378488186241024     319.793549\n",
       "...                     ...            ...\n",
       "3500142  173398446900080640     846.284729\n",
       "3500143  173399537822896128     227.922485\n",
       "3500144  173402213585080320     239.218277\n",
       "3500145  173401960184356864     271.998993\n",
       "3500146  173403669580005376     197.939407\n",
       "\n",
       "[3500147 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43558f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"AutoGlon_Ensemble.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5311990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: agModels-regression_Best_Quality/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: agModels-regression_Best_Quality/models/WeightedEnsemble_L3/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                   model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBMXT_BAG_L2  -0.166128    1779.297951  8690.788978              326.516364        3083.951241            2       True          5\n",
      "1    WeightedEnsemble_L3  -0.166128    1779.428631  8690.947938                0.130680           0.158960            3       True          6\n",
      "2    WeightedEnsemble_L2  -0.248124    1029.647549  5667.691353                0.130462         118.102494            2       True          4\n",
      "3  KNeighborsDist_BAG_L1  -0.256312     460.699891    58.411044              460.699891          58.411044            1       True          2\n",
      "4  KNeighborsUnif_BAG_L1  -0.305161     423.264500    57.248878              423.264500          57.248878            1       True          1\n",
      "5      LightGBMXT_BAG_L1  -0.693445     568.817196  5491.177815              568.817196        5491.177815            1       True          3\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 2 | ['prior_avg_fee_charged', 'final_fee_bid']\n",
      "('int', [])       : 5 | ['prior_ledger_sequence', 'prior_operation_count', 'prior_max_fee_charged', 'prior_min_fee_charged', 'transaction_operation_count']\n",
      "('int', ['bool']) : 1 | ['sponsor']\n",
      "Plot summary of models saved to file: agModels-regression_Best_Quality/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d6f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
